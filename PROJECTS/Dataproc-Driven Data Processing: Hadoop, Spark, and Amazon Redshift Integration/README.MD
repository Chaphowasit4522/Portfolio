# Dataproc-Driven Data Processing: Hadoop-Spark, Amazon Redshift and Amazon QuickSight Integration üêò

# Introduction
Embark on a transformative data processing journey with our project, "Dataproc-Driven Data Processing: Hadoop, Spark, Redshift, and QuickSight Integration." This endeavor harnesses the power of Google Cloud Dataproc to orchestrate a seamless Hadoop-Spark pipeline, enabling efficient data manipulation and analytics on Google Cloud Storage. Integrated with Jupyter Notebook and powered by PySpark, our solution ensures a user-friendly data exploration experience. The final destination for our processed data is AWS Redshift, a fully managed data warehouse, promising scalability and accessibility for comprehensive business intelligence and analytics. Furthermore, AWS QuickSight is seamlessly integrated for advanced data visualization, adding an extra layer of insight to your analytics. Join us in navigating the convergence of Dataproc, Hadoop, Spark, Redshift, and QuickSight, creating a unified and insightful data processing experience.

# Data Description
The dataset, spanning from 2014 to 2017, encapsulates information on crime incidents with a focus on major offenses. Each record details the geographic coordinates (X, Y) of the event location, a unique event identifier (event_unique_id), occurrence and reported dates, premise type (premisetype), Uniform Crime Reporting (UCR) codes, offense type, and various temporal components such as reported and occurrence years, months, days, and hours. Additional attributes include the Major Crime Indicator (MCI) category, police division (Division), neighborhood ID (Hood_ID), neighborhood name, and geographical coordinates (Lat, Long). This dataset serves as a valuable resource for analyzing crime patterns, trends, and their spatial-temporal dynamics over the specified period.

# Technologies & Tools
Big Data Processing: Apache Hadoop, Apache Spark <br>
Cloud Platform: GCP, AWS <br> 
Data Exploration: Jupyter Notebooks with Python <br>
Data Storage: Google Cloud Storage (GCS), AWS Redshift <br>
Data Visualization: AWS QuickSight <br>
Programming Languages: Python (PySpark and Pandas) <br>

# Data Flow & Diagram

# Project Overview
This project, titled "Dataproc-Driven Data Processing: Hadoop, Spark, Redshift, and QuickSight Integration," aims to create a streamlined and integrated data processing pipeline. Leveraging Google Cloud Dataproc, Apache Hadoop, Apache Spark, AWS Redshift, and AWS QuickSight, the objective is to orchestrate a seamless Hadoop-Spark workflow for efficient data manipulation and analytics on Google Cloud Storage. The solution, integrated with Jupyter Notebook and powered by PySpark, ensures a user-friendly data exploration experience. The final outcome involves storing processed data in AWS Redshift, a fully managed data warehouse, and utilizing AWS QuickSight for advanced data visualization and business intelligence. This project seeks to deliver a unified and insightful data processing experience, enabling users to efficiently explore, manipulate, and analyze large datasets for informed decision-making.

# Before Start
1. You need to 

# Process



# 

